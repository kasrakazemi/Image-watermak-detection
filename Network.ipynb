{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data from the folders created to hold the original images and their corresponding image with a watermark. Standardize and reshape the images to fit into the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4291 images belonging to 1 classes.\n",
      "Found 4291 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_dir = 'C:/Users/kasra/Desktop/Cup/2/dataset/train/negative'\n",
    "wat_dir = 'C:/Users/kasra/Desktop/Cup/2/dataset/train/positive'\n",
    "\n",
    "raw_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "raw_generator = raw_datagen.flow_from_directory(\n",
    "        raw_dir,  # this is the target directory\n",
    "        target_size=(250, 250),\n",
    "        batch_size=5096, shuffle = False,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "wat_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "wat_generator = wat_datagen.flow_from_directory(\n",
    "        wat_dir,  # this is the target directory\n",
    "        target_size=(250, 250),\n",
    "        batch_size=5096, shuffle = 0,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "x_raw,y = raw_generator.next()\n",
    "x_wat,y = wat_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1103 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'C:/Users/kasra/Desktop/Cup/2/dataset/test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,  # this is the target directory\n",
    "        target_size=(250, 250),\n",
    "        batch_size=1103, shuffle = False,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "x_test,y_test = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4291, 250, 250, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw = x_raw[0:200]\n",
    "x_train_wat = x_wat[0:200]\n",
    "\n",
    "x_val_raw = x_raw[200:250]\n",
    "x_val_wat = x_wat[200:250]\n",
    "\n",
    "x_train = np.vstack((x_train_raw, x_train_wat))\n",
    "x_val = np.vstack((x_val_raw, x_val_wat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.repeat([0.], 200)\n",
    "y_train = np.append(y_train, np.repeat([1.], 200))\n",
    "\n",
    "y_val = np.repeat([0.], 50)\n",
    "y_val = np.append(y_val, np.repeat([1.], 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 250, 250, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the response variables for each data set: images with a watermark have a response of 1, while images without a watermark have a response of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='elu', input_shape=(250, 250, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='elu'))\n",
    "model.add(layers.Conv2D(100, (3, 3), activation='elu'))\n",
    "model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "model.add(layers.Conv2D(75, (3, 3), activation='elu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(202, activation='elu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(40, activation='elu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "#model.summary()\n",
    "history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 12, \n",
    "          batch_size = 25, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(x_test[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0e80bf90ef94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myhat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'yhat' is not defined"
     ]
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.833861431106925,\n",
       "  0.7269358411431313,\n",
       "  0.7108206525444984,\n",
       "  0.684205686673522,\n",
       "  0.6834716014564037,\n",
       "  0.6433127103373408,\n",
       "  0.6230340581387281,\n",
       "  0.6053322069346905,\n",
       "  0.5718950042501092,\n",
       "  0.5327417440712452,\n",
       "  0.43991149589419365,\n",
       "  0.43052427656948566],\n",
       " 'acc': [0.51125,\n",
       "  0.50375,\n",
       "  0.52375,\n",
       "  0.5525,\n",
       "  0.57625,\n",
       "  0.655,\n",
       "  0.65375,\n",
       "  0.68125,\n",
       "  0.6725,\n",
       "  0.73875,\n",
       "  0.79125,\n",
       "  0.8075],\n",
       " 'val_loss': [0.6784938126802444,\n",
       "  0.7163877189159393,\n",
       "  0.6657157093286514,\n",
       "  0.6721587628126144,\n",
       "  0.6005875021219254,\n",
       "  0.6310412362217903,\n",
       "  0.5681379362940788,\n",
       "  0.5793224424123764,\n",
       "  0.6009222939610481,\n",
       "  0.5103896260261536,\n",
       "  0.43254416808485985,\n",
       "  0.515699714422226],\n",
       " 'val_acc': [0.56,\n",
       "  0.53,\n",
       "  0.6,\n",
       "  0.58,\n",
       "  0.71,\n",
       "  0.67,\n",
       "  0.73,\n",
       "  0.69,\n",
       "  0.68,\n",
       "  0.75,\n",
       "  0.8,\n",
       "  0.77]}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
